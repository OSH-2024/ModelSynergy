# 系统LLM助理-ModelSynergy

- [系统LLM助理-ModelSynergy](#系统llm助理-modelsynergy)
  - [项目简介](#项目简介)
    - [项目内容简介](#项目内容简介)
    - [预期目标](#预期目标)
  - [项目背景调研](#项目背景调研)
  - [技术路线](#技术路线)
    - [InfLLM](#infllm)
    - [KVcache](#kvcache)
    - [实时监控与更新](#实时监控与更新)
      - [文件修改监视](#文件修改监视)
      - [消息队列](#消息队列)
  - [实现效果展示](#实现效果展示)
    - [KVcache加速与实时监控](#kvcache加速与实时监控)
    - [信息检索](#信息检索)
    - [长上下文效果](#长上下文效果)
  - [实现结果分析](#实现结果分析)
  - [总结与展望](#总结与展望)
    - [工作进展与分工](#工作进展与分工)
    - [项目进度](#项目进度)
    - [不足](#不足)
    - [后期展望](#后期展望)
  - [参考文献与相关链接](#参考文献与相关链接)
  - [鸣谢](#鸣谢)


## 项目简介

### 项目内容简介

**基于`InfLLM`长上下文技术，结合`KVcache`加速推理过程，通过下端引入`open-interpreter`技术使得模型基于本地操作系统的用户内容，生成用户个性化的，更细粒度符合用户操作习惯、需求的命令，将LLM作为Agent引入操作系统，增强操作系统的用户友好性，使得操作系统更加自动化、智能化。**
本项目的重点在于如何将LLM与操作系统耦合，使得其在内核与用户间提供一个更用户友好的、更便于操作的中间层。

### 预期目标

我们将LLM的上下文机制引入操作系统，希望使得操作系统的文件系统等成为上下文的组成部分，提高LLM对用户的个性化适用性。并且希望通过KVcache的引入，加速推理过程使得相应速度提高，更符合用户需求，实时监控文件系统更改，修改KVcache，并引入interpreter等工具生成操作命令，对用户更友好，更易操作。

## 项目背景调研

## 技术路线

### InfLLM

### KVcache

### 实时监控与更新

#### 文件修改监视

#### 消息队列

## 实现效果展示

### KVcache加速与实时监控

### 信息检索

### 长上下文效果

## 实现结果分析


## 总结与展望

### 工作进展与分工

### 项目进度

### 不足

### 后期展望

## 参考文献与相关链接

## 鸣谢